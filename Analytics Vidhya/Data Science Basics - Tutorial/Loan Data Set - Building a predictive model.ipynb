{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analysis\n",
    "\n",
    "Tutorial Source: https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/\n",
    "\n",
    "Sklearn Refresher: https://www.analyticsvidhya.com/blog/2015/01/scikit-learn-python-machine-learning-tool/\n",
    "\n",
    "Sklearn Cheat Sheet: http://peekaboo-vision.blogspot.co.uk/2013/01/machine-learning-cheat-sheet-for-scikit.html\n",
    "\n",
    "Python Machine Learning Essentials: https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/\n",
    "\n",
    "Python Cross-Validation: https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/\n",
    "\n",
    "Additional Libraries: NumPy, SciPy\n",
    "\n",
    "We will first load our libraries and then the post-processed train data set in order to begin our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>LoanAmount_log</th>\n",
       "      <th>TotalIncome</th>\n",
       "      <th>TotalIncome_log</th>\n",
       "      <th>LoanByIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.986426</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>8.674026</td>\n",
       "      <td>16.879378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>8.714568</td>\n",
       "      <td>14.688050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>8.243439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>8.505323</td>\n",
       "      <td>14.108812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.948760</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>8.699515</td>\n",
       "      <td>16.207801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0           0  LP001002   Male      No          0      Graduate            No   \n",
       "1           1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2           2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3           3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4           4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0  146.412162             360.0   \n",
       "1             4583             1508.0  128.000000             360.0   \n",
       "2             3000                0.0   66.000000             360.0   \n",
       "3             2583             2358.0  120.000000             360.0   \n",
       "4             6000                0.0  141.000000             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  LoanAmount_log  TotalIncome  \\\n",
       "0             1.0         Urban           Y        4.986426       5849.0   \n",
       "1             1.0         Rural           N        4.852030       6091.0   \n",
       "2             1.0         Urban           Y        4.189655       3000.0   \n",
       "3             1.0         Urban           Y        4.787492       4941.0   \n",
       "4             1.0         Urban           Y        4.948760       6000.0   \n",
       "\n",
       "   TotalIncome_log  LoanByIncome  \n",
       "0         8.674026     16.879378  \n",
       "1         8.714568     14.688050  \n",
       "2         8.006368      8.243439  \n",
       "3         8.505323     14.108812  \n",
       "4         8.699515     16.207801  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"post_processed_csv.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a few missing values in some of the categorical variables, therefore we will impute data to solve this. Categorical values need a slightly different approach to imputing in comparison with numerical values because you can't take a mean of a categorical value range for example.\n",
    "\n",
    "Here, we take the most commonly occuring categorical value from the value counts table and replace the missing values with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "LoanAmount_log       0\n",
       "TotalIncome          0\n",
       "TotalIncome_log      0\n",
       "LoanByIncome         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Credit_History\"] = df[\"Credit_History\"].fillna(df[\"Credit_History\"].value_counts().index[0])\n",
    "df[\"Gender\"] = df[\"Gender\"].fillna(df[\"Gender\"].value_counts().index[0])\n",
    "df[\"Married\"] = df[\"Married\"].fillna(df[\"Married\"].value_counts().index[0])\n",
    "df[\"Dependents\"] = df[\"Dependents\"].fillna(df[\"Dependents\"].value_counts().index[0])\n",
    "df[\"Loan_Amount_Term\"] = df[\"Loan_Amount_Term\"].fillna(df[\"Loan_Amount_Term\"].value_counts().index[0])\n",
    "\n",
    "df.apply(func=lambda x: sum(x.isnull()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a complete data set to work with, we need to convert our categorical variables into numerical values because sklearn cannot work with categorical variables.\n",
    "\n",
    "We do this using label encoding, which alters the type of our categorical variables. In this case we are replacing our categorical labels with simple 1s and 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0             int64\n",
      "Loan_ID               object\n",
      "Gender                 int64\n",
      "Married                int64\n",
      "Dependents             int64\n",
      "Education              int64\n",
      "Self_Employed          int64\n",
      "ApplicantIncome        int64\n",
      "CoapplicantIncome    float64\n",
      "LoanAmount           float64\n",
      "Loan_Amount_Term     float64\n",
      "Credit_History       float64\n",
      "Property_Area          int64\n",
      "Loan_Status            int64\n",
      "LoanAmount_log       float64\n",
      "TotalIncome          float64\n",
      "TotalIncome_log      float64\n",
      "LoanByIncome         float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>LoanAmount_log</th>\n",
       "      <th>TotalIncome</th>\n",
       "      <th>TotalIncome_log</th>\n",
       "      <th>LoanByIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LP001002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.986426</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>8.674026</td>\n",
       "      <td>16.879378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LP001003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>8.714568</td>\n",
       "      <td>14.688050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LP001005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>8.243439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LP001006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>8.505323</td>\n",
       "      <td>14.108812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LP001008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.948760</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>8.699515</td>\n",
       "      <td>16.207801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Loan_ID  Gender  Married  Dependents  Education  \\\n",
       "0           0  LP001002       1        0           0          0   \n",
       "1           1  LP001003       1        1           1          0   \n",
       "2           2  LP001005       1        1           0          0   \n",
       "3           3  LP001006       1        1           0          1   \n",
       "4           4  LP001008       1        0           0          0   \n",
       "\n",
       "   Self_Employed  ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "0              0             5849                0.0  146.412162   \n",
       "1              0             4583             1508.0  128.000000   \n",
       "2              1             3000                0.0   66.000000   \n",
       "3              0             2583             2358.0  120.000000   \n",
       "4              0             6000                0.0  141.000000   \n",
       "\n",
       "   Loan_Amount_Term  Credit_History  Property_Area  Loan_Status  \\\n",
       "0             360.0             1.0              2            1   \n",
       "1             360.0             1.0              0            0   \n",
       "2             360.0             1.0              2            1   \n",
       "3             360.0             1.0              2            1   \n",
       "4             360.0             1.0              2            1   \n",
       "\n",
       "   LoanAmount_log  TotalIncome  TotalIncome_log  LoanByIncome  \n",
       "0        4.986426       5849.0         8.674026     16.879378  \n",
       "1        4.852030       6091.0         8.714568     14.688050  \n",
       "2        4.189655       3000.0         8.006368      8.243439  \n",
       "3        4.787492       4941.0         8.505323     14.108812  \n",
       "4        4.948760       6000.0         8.699515     16.207801  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "var_mod = [\"Gender\", \"Married\", \"Dependents\", \"Education\", \"Self_Employed\", \"Property_Area\", \"Loan_Status\"]\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "    \n",
    "print(df.dtypes)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is ready to be modelled, we can import the modules we will use to model, cross-validate and visualise the data.\n",
    "\n",
    "A logistic regression is a predictive analysis which determines the likely value of a binary categorical dependent variable based on one or more NOIR independent variables. Essentially, when a combination of other values change, what happens to the value we are measuring? Whereas a linear regression predicts an often numerical point as close to the actual value as it can, logistic regression is a classifier which predicts the correct binary class (0 or 1) for the outcome.\n",
    "\n",
    "Often data sets are too small to extract a sub-section from in order to use that as a test set and the rest as a training set, as such cross-validation is used. This method uses a portion of the entire data set as a test/validation set and the rest as a training set and then repeats this process using different validation sets each time so that the same data can be re-used multiple times without losing data overall whilst building the model and calculating how accurate it is. In K-Fold cross-validation the data is split into k sub-sections with the first being used as a validation set and the rest as train data, it then proceeds k times, using a different sub-section each time to test the model. This is a non-exhaustive method because every single combination of data is not used, you simply use chunks but it is still able to utilise the full data set each time. Cross-validation calculates the accuracy of the model for each validation set and then averages the results to provide a final score which has less variability than it would otherwise have.\n",
    "\n",
    "Random forests are an ensemble method, which means that they use a combination of multiple other learning algorithms in order to produce a more flexible and fair result. They are essentially multiple decision trees chained together and they take the mode class (classifier) or mean result (regression) of the individual trees results, this generally makes random forest less prone to overfitting in comparision with a single decision tree.\n",
    "\n",
    "Decision trees consist of branches and leaves, each branch checks a combination of parameters and determines which leaf the sample ends up in, it is a way of filtering a sample and making decisions at each node based on inputs/states at that point and determining the end result. For categorical/discrete variables, decision trees act as classifiers by filtering the sample into a specific leaf which represents a class, whilst for numerical values they act as regression models where the leaf value can take continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.cross_validation import KFold # deprecated, therefore use below module instead\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a general function to be used later to plug in our individual predictive model algorithms in order to run and cross-validate them simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IVE TWEAKED THIS A LOT AND ITS NOT PLAYING BALL, IT MIGHT BE WORTH USING A SEPARATE TUTORIAL TO FIGURE THIS OUT\n",
    "\n",
    "def classification_model(model, data, features, labels):\n",
    "    model.fit(data[features].values.reshape(-1,1), data[labels].values.reshape(-1,1)) # fit the model\n",
    "    predictions = model.predict(data[features].values.reshape(-1,1)) # make predictions based on train data\n",
    "    accuracy = metrics.accuracy_score(predictions, data[labels].values.reshape(-1,1)) # determine accuracy of model (predictions vs. actual)\n",
    "    print(\"Accuracy: %s\" % \"{0:.3%}\".format(accuracy))\n",
    "    \n",
    "    kf = KFold(n_splits=5) # define K-folds with 5 folds (NB: shape[0] = row count) data.shape[0], \n",
    "    error = [] # create empty array to store all k results\n",
    "    \n",
    "    for train, test in kf.split(data.shape[0]):\n",
    "        train_features = (data[features].iloc[train,:]).values.reshape(-1,1) # extract train data features (train = rows, : = all cols in features)\n",
    "        train_target = (data[labels].iloc[train]).values.reshape(-1,1) # extract train data labels (train = rows, there is only one col in labels)\n",
    "        model.fit(train_features, train_target) # train model on train features and labels\n",
    "        error.append(model.score(data[features].iloc[test,:].values.reshape(-1,1), data[labels].iloc[test]).values.reshape(-1,1)) # track all error scores from each k\n",
    "    \n",
    "    print(\"Cross-validation score: %s\" % \"{0:.3%}\".format(np.mean(error))) # print mean of errors\n",
    "        \n",
    "    model.fit(data[features], data[labels]) # fit model again so it can be referenced outside of this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression Intro: https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/\n",
    "\n",
    "Basic Linear Regression: https://www.analyticsvidhya.com/blog/2015/10/regression-python-beginners/\n",
    "\n",
    "We can have a go at using our first learning algorithm, the logistic regression. We could load all of our independent/predictor variables into the model but this can result in overfitting due to identifying complex relationships which are specific to this individual data set, so instead we will analyse individual (simple, rather than multiple) independent to dependent variable relationships.\n",
    "\n",
    "We can already state a few initial hypotheses from our initial analysis, that the chances of getting a loan will be higher for:\n",
    "* People with an existing credit score\n",
    "* People with higher educations\n",
    "* People with higher income and co-incomes\n",
    "* People living in urban areas with good development prospects\n",
    "\n",
    "We will begin by building our first logistic regression model using the credit history variable (which has now been converted from a categorical labelled variable into a binary numeric variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.945%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(614) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-31b2764b1687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Credit_History'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Loan_Status'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassification_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-87a23bfe6390>\u001b[0m in \u001b[0;36mclassification_model\u001b[0;34m(model, data, features, labels)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# create empty array to store all k results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# extract train data features (train = rows, : = all cols in features)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# extract train data labels (train = rows, there is only one col in labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \"\"\"\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 126\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(614) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "features_var = 'Credit_History'\n",
    "labels_var = 'Loan_Status'\n",
    "classification_model(model, df, features_var, labels_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "* Make notes on the different types of classifiers which will be used.\n",
    "* Understand the parameters and inputs.\n",
    "* Understand the logic of each process and what it's looking at and predicting.\n",
    "* Detail how the cross-validation works and what it shows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
